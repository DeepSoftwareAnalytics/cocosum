{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:35:51.959998Z",
     "start_time": "2021-06-16T08:35:51.278981Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:35:52.995271Z",
     "start_time": "2021-06-16T08:35:51.965000Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate cliffs delta effect size: https://github.com/neilernst/cliffsDelta/blob/master/cliffsDelta.py\n",
    "from __future__ import division\n",
    "import copy\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def cliffsDelta(lst1, lst2, **dull):\n",
    "    \"\"\"Returns delta and true if there are more than 'dull' differences\"\"\"\n",
    "    if not dull:\n",
    "        dull = {'small': 0.147, 'medium': 0.33, 'large': 0.474} # effect sizes from (Hess and Kromrey, 2004)\n",
    "    m, n = len(lst1), len(lst2)\n",
    "    lst2 = sorted(lst2)\n",
    "    j = more = less = 0\n",
    "    for repeats, x in runs(sorted(lst1)):\n",
    "        while j <= (n - 1) and lst2[j] < x:\n",
    "            j += 1\n",
    "        more += j*repeats\n",
    "        while j <= (n - 1) and lst2[j] == x:\n",
    "            j += 1\n",
    "        less += (n - j)*repeats\n",
    "    d = (more - less) / (m*n)\n",
    "    size = lookup_size(d, dull)\n",
    "    return d, size\n",
    "\n",
    "\n",
    "def lookup_size(delta: float, dull: dict) -> str:\n",
    "    \"\"\"\n",
    "    :type delta: float\n",
    "    :type dull: dict, a dictionary of small, medium, large thresholds.\n",
    "    \"\"\"\n",
    "    delta = abs(delta)\n",
    "    if delta < dull['small']:\n",
    "        return 'negligible'\n",
    "    if dull['small'] <= delta < dull['medium']:\n",
    "        return 'small'\n",
    "    if dull['medium'] <= delta < dull['large']:\n",
    "        return 'medium'\n",
    "    if delta >= dull['large']:\n",
    "        return 'large'\n",
    "\n",
    "\n",
    "def runs(lst):\n",
    "    \"\"\"Iterator, chunks repeated values\"\"\"\n",
    "    for j, two in enumerate(lst):\n",
    "        if j == 0:\n",
    "            one, i = two, 0\n",
    "        if one != two:\n",
    "            yield j - i, one\n",
    "            i = j\n",
    "        one = two\n",
    "    yield j - i + 1, two\n",
    "\n",
    "    \n",
    "### calculate wilcoxon pvalue\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def wilcoxon_signed_rank_test(y1, y2):\n",
    "    statistic,pvalue = stats.wilcoxon(y1, y2)\n",
    "    return pvalue\n",
    "\n",
    "\n",
    "def get_score(y1,y2):\n",
    "    pvalue = wilcoxon_signed_rank_test(y1, y2)\n",
    "    d, size = cliffsDelta(y1, y2)\n",
    "    return  pvalue, d, size\n",
    "\n",
    "\n",
    "def get_pvalue_and_effect_size(all_score):\n",
    "    models_name = list(all_score)\n",
    "    for i in range(len( models_name )):\n",
    "        for j in range(i+1,len( models_name )):\n",
    "            pvalue, d, size = get_score(all_score[models_name[i]],all_score[models_name[j]])\n",
    "            print(\"{} and {}, pvalue:{}, cliffsDelta:{}, effect size:{}\".format(models_name[i],models_name[j],pvalue, d, size))\n",
    "\n",
    "\n",
    "def get_all_model_score(path,question_cnt = 50):\n",
    "    data_frame=pd.read_excel(path)\n",
    "    result = {}\n",
    "    \n",
    "    user_cnt = len(data_frame[\"ID\"])\n",
    "    for i in range(user_cnt):\n",
    "        for q in range(question_cnt):\n",
    "            cocogum , ast_att_gru, astnn, rencos = list(data_frame.loc[i])[5+4*q:9+4*q]\n",
    "            key = \"Q_\" + str(q)\n",
    "            if key in result:\n",
    "                result[ key][ \"cocogum\" ].append(cocogum)\n",
    "                result[ key][ \"ast_att_gru\" ].append( ast_att_gru)\n",
    "                result[ key][ \"astnn\" ].append(astnn)\n",
    "                result[ key][ \"rencos\" ].append(rencos)\n",
    "            else:\n",
    "                result[ key] = {}\n",
    "                result[ key][ \"cocogum\" ] = [cocogum]\n",
    "                result[ key][ \"ast_att_gru\" ] = [ast_att_gru]\n",
    "                result[ key][ \"astnn\" ] = [astnn]\n",
    "                result[ key][ \"rencos\" ] = [rencos]\n",
    "\n",
    "    cocogum_scores = []\n",
    "    ast_att_gru_scores = []\n",
    "    astnn_scores = []\n",
    "    rencos_scores = []\n",
    "    for q, four_score in result.items():\n",
    "        cocogum_scores.extend(four_score[\"cocogum\"])\n",
    "        ast_att_gru_scores.extend(four_score[\"ast_att_gru\"])\n",
    "        astnn_scores.extend(four_score[\"astnn\"])\n",
    "        rencos_scores.extend(four_score[\"rencos\"])\n",
    "\n",
    "    all_score = {\"cocogum\":cocogum_scores,\"ast_att_gru\":ast_att_gru_scores,\"astnn\":astnn_scores,\"rencos\":rencos_scores }\n",
    "    return all_score\n",
    "\n",
    "\n",
    "def parse_score_dict(result):\n",
    "    cocogum_scores = []\n",
    "    ast_att_gru_scores = []\n",
    "    astnn_scores = []\n",
    "    rencos_scores = []\n",
    "    for q, four_score in result.items():\n",
    "        cocogum_scores.extend(four_score[\"cocogum\"])\n",
    "        ast_att_gru_scores.extend(four_score[\"ast_att_gru\"])\n",
    "        astnn_scores.extend(four_score[\"astnn\"])\n",
    "        rencos_scores.extend(four_score[\"rencos\"])\n",
    "\n",
    "    all_score = {\"cocogum\":cocogum_scores,\"ast_att_gru\":ast_att_gru_scores,\"astnn\":astnn_scores,\"rencos\":rencos_scores }\n",
    "    return all_score\n",
    "\n",
    "\n",
    "def get_all_model_in_three_aspects_score(path,question_cnt = 10,start_qid=1):\n",
    "    model_order_dict = {}\n",
    "    for i in range(1, 51,1):\n",
    "        random.seed(i)\n",
    "        li= [1,2,3,4]\n",
    "        random.shuffle(li)\n",
    "        model_order_dict[i] =  li    \n",
    "#     print('model_order_dict:', model_order_dict)\n",
    "    \n",
    "#     path = \"112506357_2_Code Summarization Human Evaluation 1- 10_2_2.xlsx\"\n",
    "    data_frame=pd.read_excel(path)\n",
    "    result = {\"informative\":{}, \"naturalness\":{}, \"similarity\":{}}\n",
    "    user_cnt = len(data_frame[\"序号\"])\n",
    "    for i in range(user_cnt):\n",
    "        for q in range(question_cnt):\n",
    "            start_index = 6 + q*12\n",
    "            one_question_score = [list(data_frame.loc[0])[start_index+j*3:start_index+(j+1)*3] for j in range(4)]\n",
    "            model_order_in_this_question = model_order_dict[q+start_qid]\n",
    "            one_question_model_socre = dict (zip(model_order_in_this_question,one_question_score  ))\n",
    "            ast_att_gru, astnn, rencos, cocogum = one_question_model_socre[1], \\\n",
    "                                                  one_question_model_socre[2], \\\n",
    "                                                  one_question_model_socre[3], \\\n",
    "                                                  one_question_model_socre[4]\n",
    "            key = \"Q_\" + str(q)\n",
    "            if key in result[\"informative\"]:\n",
    "                result[\"informative\"][ key][ \"cocogum\" ].append(cocogum[0]-1)\n",
    "                result[\"informative\"][ key][ \"ast_att_gru\" ].append( ast_att_gru[0]-1)\n",
    "                result[\"informative\"][ key][ \"astnn\" ].append(astnn[0]-1)\n",
    "                result[\"informative\"][ key][ \"rencos\" ].append(rencos[0]-1)\n",
    "\n",
    "                result[\"naturalness\"][ key][ \"cocogum\" ].append(cocogum[1]-1)\n",
    "                result[\"naturalness\"][ key][ \"ast_att_gru\" ].append( ast_att_gru[1]-1)\n",
    "                result[\"naturalness\"][ key][ \"astnn\" ].append(astnn[1]-1)\n",
    "                result[\"naturalness\"][ key][ \"rencos\" ].append(rencos[1]-1)\n",
    "\n",
    "                result[\"similarity\"][ key][ \"cocogum\" ].append(cocogum[2]-1)\n",
    "                result[\"similarity\"][ key][ \"ast_att_gru\" ].append( ast_att_gru[2]-1)\n",
    "                result[\"similarity\"][ key][ \"astnn\" ].append(astnn[2]-1)\n",
    "                result[\"similarity\"][ key][ \"rencos\" ].append(rencos[2]-1)\n",
    "            else:\n",
    "                result[\"informative\"] [ key] = {}\n",
    "                result[\"naturalness\"][ key]= {}\n",
    "                result[\"similarity\"][ key] = {}\n",
    "\n",
    "                result[\"informative\"][ key][ \"cocogum\" ]= [cocogum[0]-1]\n",
    "                result[\"informative\"][ key][ \"ast_att_gru\" ]=  [ast_att_gru[0]-1]\n",
    "                result[\"informative\"][ key][ \"astnn\" ] = [astnn[0]-1]\n",
    "                result[\"informative\"][ key][ \"rencos\" ] = [rencos[0]-1]\n",
    "\n",
    "                result[\"naturalness\"][ key][ \"cocogum\" ] = [cocogum[1]-1]\n",
    "                result[\"naturalness\"][ key][ \"ast_att_gru\" ] = [ast_att_gru[1]-1-1]\n",
    "                result[\"naturalness\"][ key][ \"astnn\" ] = [astnn[1]-1]\n",
    "                result[\"naturalness\"][ key][ \"rencos\" ] = [rencos[1]-1]\n",
    "\n",
    "                result[\"similarity\"][ key][ \"cocogum\" ] = [cocogum[2]-1]\n",
    "                result[\"similarity\"][ key][ \"ast_att_gru\" ] =  [ast_att_gru[2]-1]\n",
    "                result[\"similarity\"][ key][ \"astnn\" ] = [astnn[2]-1]\n",
    "                result[\"similarity\"][ key][ \"rencos\" ] = [rencos[2]-1]\n",
    "    return  parse_score_dict(result['informative']), parse_score_dict(result['naturalness']), parse_score_dict(result['similarity'])\n",
    "\n",
    "\n",
    "def print_distribution(four_model_score):\n",
    "    table = PrettyTable(['model type', \"0\", \"1\", \"2\", \"3\", \"4\", \"Avg(Std)\", \"≥3\", \"≥2\", \"≤1\"])\n",
    "    for k in four_model_score:\n",
    "        result = Counter(four_model_score[k])\n",
    "        avg = np.mean(four_model_score[k])\n",
    "        std = np.std(four_model_score[k])\n",
    "        table.add_row([k, result[0], result[1], result[2], result[3], result[4],\n",
    "                       \"{}({})\".format(round(avg,2), round(std,2)),\n",
    "                       result[3]+result[4], result[2]+result[3]+result[4], result[0]+result[1]])\n",
    "    print(table)\n",
    "\n",
    "\n",
    "# multi-excel\n",
    "def merge_all_score(s1,s2,s3,s4,s5):\n",
    "    merged_scores = copy.deepcopy(s1)\n",
    "    five_score = [s1,s2,s3,s4,s5 ]\n",
    "    for key in merged_scores[0].keys():\n",
    "        for i in range(3):\n",
    "            for j in range(1,len(five_score)):\n",
    "                merged_scores[i][key].extend(five_score[j][i][key])\n",
    "    return  merged_scores\n",
    "\n",
    "\n",
    "def calcute_final_result(path1,path2,path3,path4,path5):\n",
    "    all_scores1_10 = get_all_model_in_three_aspects_score(path1,question_cnt=10,start_qid=1)\n",
    "    all_scores11_20 = get_all_model_in_three_aspects_score(path2,question_cnt=10,start_qid=11)\n",
    "    all_scores21_30 = get_all_model_in_three_aspects_score(path3,question_cnt=10,start_qid=21)\n",
    "    all_scores31_40 = get_all_model_in_three_aspects_score(path4,question_cnt=10,start_qid=31)\n",
    "    all_scores41_50 = get_all_model_in_three_aspects_score(path5,question_cnt=10,start_qid=41)\n",
    "    merged_scores = merge_all_score(all_scores1_10,all_scores11_20 ,all_scores21_30 ,all_scores31_40 ,all_scores41_50 )\n",
    "    print(\"informative\")\n",
    "    print_distribution( merged_scores[0])\n",
    "    get_pvalue_and_effect_size( merged_scores[0])\n",
    "    \n",
    "    print(80*\"*\")\n",
    "    print(\"naturalness\")\n",
    "    print_distribution( merged_scores[1])\n",
    "    get_pvalue_and_effect_size( merged_scores[1])\n",
    "    \n",
    "    print(80*\"*\")\n",
    "    print(\"similarity\")\n",
    "    print_distribution( merged_scores[2])\n",
    "    get_pvalue_and_effect_size( merged_scores[2])\n",
    "    return merged_scores\n",
    "\n",
    "\n",
    "def main():\n",
    "    path1_10 = r\"112506357_2_Code Summarization Human Evaluation 1- 10_4_4.xlsx\"\n",
    "    path11_20 = r\"112506178_2_Code Summarization Human Evaluation 11- 20_4_4.xlsx\"\n",
    "    path21_30 = r\"112506168_2_Code Summarization Human Evaluation 21- 30_4_4.xlsx\"\n",
    "    path31_40 = r\"112506604_2_Code Summarization Human Evaluation 31- 40_4_4.xlsx\"\n",
    "    path41_50 = r\"112504929_2_Code Summarization Human Evaluation 41- 50_4_4.xlsx\"\n",
    "    scores = calcute_final_result(path1_10, path11_20, path21_30, path31_40, path41_50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 appraoch 3 aspect 50 question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:35:53.010776Z",
     "start_time": "2021-06-16T08:35:53.000274Z"
    }
   },
   "outputs": [],
   "source": [
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:35:53.041316Z",
     "start_time": "2021-06-16T08:35:53.013305Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_alpha_for_4_raters_in_one_group_question_one_approach( all_scores, approach, aspect):\n",
    "    aspects = {0:\"informative\", 1:\"naturalness\", 2:\"similarity\"}\n",
    "    score_cocogum = all_scores[aspect][approach]\n",
    "    rater0_range = list(range(0,40,4))\n",
    "    rater1_range = list(range(1,40,4))\n",
    "    rater2_range = list(range(1,40,4))\n",
    "    rater3_range = list(range(1,40,4))\n",
    "    rater0 = [ score_cocogum[item] for item in rater0_range]\n",
    "    rater1 = [ score_cocogum[item] for item in rater1_range]\n",
    "    rater2 = [ score_cocogum[item] for item in rater2_range]\n",
    "    rater3 = [ score_cocogum[item] for item in rater3_range]\n",
    "    all_raters_score = [rater0,rater1,rater2,rater3]\n",
    "    print(\" %s in %s: \"%(approach,aspects[aspect]) + \"Krippendorff's alpha for ordinal metric: {}\".format(krippendorff.alpha(reliability_data=all_raters_score ,level_of_measurement='ordinal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:35:53.056815Z",
     "start_time": "2021-06-16T08:35:53.042817Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_alpha_for_4_raters_in_one_group_question(all_scores):\n",
    "    approaches=['cocogum', 'ast_att_gru', 'astnn', 'rencos']\n",
    "    for aspect in range(3):\n",
    "        for approach in approaches:\n",
    "            get_alpha_for_4_raters_in_one_group_question_one_approach( all_scores, approach, aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:46:36.923491Z",
     "start_time": "2021-06-16T08:46:36.633487Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "112506357_2_Code Summarization Human Evaluation 1- 10_4_4.xlsx\n",
      " cocogum in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in naturalness: Krippendorff's alpha for ordinal metric: 0.5966803278688524\n",
      " astnn in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112506178_2_Code Summarization Human Evaluation 11- 20_4_4.xlsx\n",
      " cocogum in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in naturalness: Krippendorff's alpha for ordinal metric: 0.3836326458036984\n",
      " astnn in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112506168_2_Code Summarization Human Evaluation 21- 30_4_4.xlsx\n",
      " cocogum in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in naturalness: Krippendorff's alpha for ordinal metric: 0.844545589840262\n",
      " astnn in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112506604_2_Code Summarization Human Evaluation 31- 40_4_4.xlsx\n",
      " cocogum in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in naturalness: Krippendorff's alpha for ordinal metric: 0.5762780343007916\n",
      " astnn in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112504929_2_Code Summarization Human Evaluation 41- 50_4_4.xlsx\n",
      " cocogum in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in naturalness: Krippendorff's alpha for ordinal metric: 0.7224000624609619\n",
      " astnn in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in similarity: Krippendorff's alpha for ordinal metric: 1.0\n"
     ]
    }
   ],
   "source": [
    "path1_10 = r\"112506357_2_Code Summarization Human Evaluation 1- 10_4_4.xlsx\"\n",
    "path11_20 = r\"112506178_2_Code Summarization Human Evaluation 11- 20_4_4.xlsx\"\n",
    "path21_30 = r\"112506168_2_Code Summarization Human Evaluation 21- 30_4_4.xlsx\"\n",
    "path31_40 = r\"112506604_2_Code Summarization Human Evaluation 31- 40_4_4.xlsx\"\n",
    "path41_50 = r\"112504929_2_Code Summarization Human Evaluation 41- 50_4_4.xlsx\"\n",
    "all_scores1_10 = get_all_model_in_three_aspects_score(path1_10 ,question_cnt=10,start_qid=1)\n",
    "print(80*\"*\")\n",
    "print(path1_10)\n",
    "\n",
    "get_alpha_for_4_raters_in_one_group_question(all_scores1_10)\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path11_20)\n",
    "all_scores11_20 = get_all_model_in_three_aspects_score(path11_20,question_cnt=10,start_qid=11)\n",
    "get_alpha_for_4_raters_in_one_group_question(all_scores11_20)\n",
    "\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path21_30)\n",
    "all_scores21_30 = get_all_model_in_three_aspects_score(path21_30,question_cnt=10,start_qid=21)\n",
    "get_alpha_for_4_raters_in_one_group_question(all_scores21_30)\n",
    "\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path31_40)\n",
    "all_scores31_40 = get_all_model_in_three_aspects_score(path31_40,question_cnt=10,start_qid=31)\n",
    "get_alpha_for_4_raters_in_one_group_question(all_scores31_40)\n",
    "\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path41_50)\n",
    "all_scores41_50 = get_all_model_in_three_aspects_score(path41_50,question_cnt=10,start_qid=41)\n",
    "get_alpha_for_4_raters_in_one_group_question(all_scores41_50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4 appraoch  50 question (concat 3 aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:54:19.127141Z",
     "start_time": "2021-06-16T08:54:19.118137Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_alpha_for_4_raters_in_one_group_question_one_approach_concat_three_aspect( all_scores, approach):\n",
    "    rater0_in_three_aspects = []\n",
    "    rater1_in_three_aspects = []\n",
    "    rater2_in_three_aspects = []\n",
    "    rater3_in_three_aspects = []\n",
    "        \n",
    "    aspects = {0:\"informative\", 1:\"naturalness\", 2:\"similarity\"}\n",
    "    for aspect in range(3):\n",
    "        score_cocogum = all_scores[aspect][approach]\n",
    "        rater0_range = list(range(0,40,4))\n",
    "        rater1_range = list(range(1,40,4))\n",
    "        rater2_range = list(range(1,40,4))\n",
    "        rater3_range = list(range(1,40,4))\n",
    "        rater0 = [ score_cocogum[item] for item in rater0_range]\n",
    "        rater1 = [ score_cocogum[item] for item in rater1_range]\n",
    "        rater2 = [ score_cocogum[item] for item in rater2_range]\n",
    "        rater3 = [ score_cocogum[item] for item in rater3_range]\n",
    "        rater0_in_three_aspects .extend( rater0)\n",
    "        rater1_in_three_aspects .extend( rater1)\n",
    "        rater2_in_three_aspects .extend( rater2)\n",
    "        rater3_in_three_aspects .extend( rater3)\n",
    "    all_raters_score = [rater0_in_three_aspects,rater1_in_three_aspects,rater2_in_three_aspects,rater3_in_three_aspects]\n",
    "    print(\" %s in three aspect: \"%(approach) + \"Krippendorff's alpha for ordinal metric: {}\".format(krippendorff.alpha(reliability_data=all_raters_score ,level_of_measurement='ordinal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:54:19.401237Z",
     "start_time": "2021-06-16T08:54:19.392735Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_alpha_for_4_raters_in_one_group_question_concat_three_aspect(all_scores):\n",
    "    approaches=['cocogum', 'ast_att_gru', 'astnn', 'rencos']\n",
    "    for approach in approaches:\n",
    "    #     get_alpha_for_4_raters_in_one_group_question_one_approach( all_scores, approach, aspect)\n",
    "        get_alpha_for_4_raters_in_one_group_question_one_approach_concat_three_aspect( all_scores, approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:54:20.144635Z",
     "start_time": "2021-06-16T08:54:19.888502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "112506357_2_Code Summarization Human Evaluation 1- 10_4_4.xlsx\n",
      " cocogum in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in three aspect: Krippendorff's alpha for ordinal metric: 0.872550441403958\n",
      " astnn in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112506178_2_Code Summarization Human Evaluation 11- 20_4_4.xlsx\n",
      " cocogum in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in three aspect: Krippendorff's alpha for ordinal metric: 0.9304948946043319\n",
      " astnn in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112506168_2_Code Summarization Human Evaluation 21- 30_4_4.xlsx\n",
      " cocogum in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in three aspect: Krippendorff's alpha for ordinal metric: 0.943262989315504\n",
      " astnn in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112506604_2_Code Summarization Human Evaluation 31- 40_4_4.xlsx\n",
      " cocogum in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in three aspect: Krippendorff's alpha for ordinal metric: 0.9452227564102564\n",
      " astnn in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      "********************************************************************************\n",
      "112504929_2_Code Summarization Human Evaluation 41- 50_4_4.xlsx\n",
      " cocogum in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in three aspect: Krippendorff's alpha for ordinal metric: 0.9223358724674101\n",
      " astnn in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in three aspect: Krippendorff's alpha for ordinal metric: 1.0\n"
     ]
    }
   ],
   "source": [
    "path1_10 = r\"112506357_2_Code Summarization Human Evaluation 1- 10_4_4.xlsx\"\n",
    "path11_20 = r\"112506178_2_Code Summarization Human Evaluation 11- 20_4_4.xlsx\"\n",
    "path21_30 = r\"112506168_2_Code Summarization Human Evaluation 21- 30_4_4.xlsx\"\n",
    "path31_40 = r\"112506604_2_Code Summarization Human Evaluation 31- 40_4_4.xlsx\"\n",
    "path41_50 = r\"112504929_2_Code Summarization Human Evaluation 41- 50_4_4.xlsx\"\n",
    "all_scores1_10 = get_all_model_in_three_aspects_score(path1_10 ,question_cnt=10,start_qid=1)\n",
    "print(80*\"*\")\n",
    "print(path1_10)\n",
    "\n",
    "get_alpha_for_4_raters_in_one_group_question_concat_three_aspect(all_scores1_10)\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path11_20)\n",
    "all_scores11_20 = get_all_model_in_three_aspects_score(path11_20,question_cnt=10,start_qid=11)\n",
    "get_alpha_for_4_raters_in_one_group_question_concat_three_aspect(all_scores11_20)\n",
    "\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path21_30)\n",
    "all_scores21_30 = get_all_model_in_three_aspects_score(path21_30,question_cnt=10,start_qid=21)\n",
    "get_alpha_for_4_raters_in_one_group_question_concat_three_aspect(all_scores21_30)\n",
    "\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path31_40)\n",
    "all_scores31_40 = get_all_model_in_three_aspects_score(path31_40,question_cnt=10,start_qid=31)\n",
    "get_alpha_for_4_raters_in_one_group_question_concat_three_aspect(all_scores31_40)\n",
    "\n",
    "\n",
    "print(80*\"*\")\n",
    "print(path41_50)\n",
    "all_scores41_50 = get_all_model_in_three_aspects_score(path41_50,question_cnt=10,start_qid=41)\n",
    "get_alpha_for_4_raters_in_one_group_question_concat_three_aspect(all_scores41_50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"informative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:17:30.475515Z",
     "start_time": "2021-06-16T08:17:30.464531Z"
    }
   },
   "outputs": [],
   "source": [
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:16:43.770226Z",
     "start_time": "2021-06-16T08:16:43.762252Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cocogum', 'ast_att_gru', 'astnn', 'rencos'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores1_10[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoCoGum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:19:31.357862Z",
     "start_time": "2021-06-16T08:19:31.341862Z"
    }
   },
   "outputs": [],
   "source": [
    "rater0_range = list(range(0,40,4))\n",
    "rater1_range = list(range(1,40,4))\n",
    "rater2_range = list(range(1,40,4))\n",
    "rater3_range = list(range(1,40,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:20:11.019418Z",
     "start_time": "2021-06-16T08:20:11.003373Z"
    }
   },
   "outputs": [],
   "source": [
    "score_cocogum = all_scores1_10[0][\"cocogum\"]\n",
    "rater0 = [ score_cocogum[item] for item in rater0_range]\n",
    "rater1 = [ score_cocogum[item] for item in rater1_range]\n",
    "rater2 = [ score_cocogum[item] for item in rater2_range]\n",
    "rater3 = [ score_cocogum[item] for item in rater3_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:21:28.937347Z",
     "start_time": "2021-06-16T08:21:28.932317Z"
    }
   },
   "outputs": [],
   "source": [
    "all_raters_score = [rater0,rater1,rater2,rater3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:21:50.464980Z",
     "start_time": "2021-06-16T08:21:50.458980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha for ordinal metric: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Krippendorff's alpha for ordinal metric: {}\".format(krippendorff.alpha(reliability_data=all_raters_score ,level_of_measurement='ordinal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:22:50.793626Z",
     "start_time": "2021-06-16T08:22:50.780409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha for ordinal metric: 1.0\n"
     ]
    }
   ],
   "source": [
    "score_cocogum = all_scores1_10[0][\"ast_att_gru\"]\n",
    "rater0 = [ score_cocogum[item] for item in rater0_range]\n",
    "rater1 = [ score_cocogum[item] for item in rater1_range]\n",
    "rater2 = [ score_cocogum[item] for item in rater2_range]\n",
    "rater3 = [ score_cocogum[item] for item in rater3_range]\n",
    "all_raters_score = [rater0,rater1,rater2,rater3]\n",
    "print(\"Krippendorff's alpha for ordinal metric: {}\".format(krippendorff.alpha(reliability_data=all_raters_score ,level_of_measurement='ordinal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:23:06.872150Z",
     "start_time": "2021-06-16T08:23:06.856051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha for ordinal metric: 1.0\n"
     ]
    }
   ],
   "source": [
    "score_cocogum = all_scores1_10[0][\"astnn\"]\n",
    "rater0 = [ score_cocogum[item] for item in rater0_range]\n",
    "rater1 = [ score_cocogum[item] for item in rater1_range]\n",
    "rater2 = [ score_cocogum[item] for item in rater2_range]\n",
    "rater3 = [ score_cocogum[item] for item in rater3_range]\n",
    "all_raters_score = [rater0,rater1,rater2,rater3]\n",
    "print(\"Krippendorff's alpha for ordinal metric: {}\".format(krippendorff.alpha(reliability_data=all_raters_score ,level_of_measurement='ordinal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:23:16.174192Z",
     "start_time": "2021-06-16T08:23:16.153136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha for ordinal metric: 1.0\n"
     ]
    }
   ],
   "source": [
    "score_cocogum = all_scores1_10[0][\"rencos\"]\n",
    "rater0 = [ score_cocogum[item] for item in rater0_range]\n",
    "rater1 = [ score_cocogum[item] for item in rater1_range]\n",
    "rater2 = [ score_cocogum[item] for item in rater2_range]\n",
    "rater3 = [ score_cocogum[item] for item in rater3_range]\n",
    "all_raters_score = [rater0,rater1,rater2,rater3]\n",
    "print(\"Krippendorff's alpha for ordinal metric: {}\".format(krippendorff.alpha(reliability_data=all_raters_score ,level_of_measurement='ordinal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:32:42.446992Z",
     "start_time": "2021-06-16T08:32:42.427995Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_alpha_for_4_raters_in_one_group_question_one_approach( all_scores, approach, aspect):\n",
    "    aspects = {0:\"informative\", 1:\"naturalness\", 2:\"similarity\"}\n",
    "    score_cocogum = all_scores[aspect][approach]\n",
    "    rater0_range = list(range(0,40,4))\n",
    "    rater1_range = list(range(1,40,4))\n",
    "    rater2_range = list(range(1,40,4))\n",
    "    rater3_range = list(range(1,40,4))\n",
    "    rater0 = [ score_cocogum[item] for item in rater0_range]\n",
    "    rater1 = [ score_cocogum[item] for item in rater1_range]\n",
    "    rater2 = [ score_cocogum[item] for item in rater2_range]\n",
    "    rater3 = [ score_cocogum[item] for item in rater3_range]\n",
    "    all_raters_score = [rater0,rater1,rater2,rater3]\n",
    "    print(\" %s in %s: \"%(approach,aspects[aspect]) + \"Krippendorff's alpha for ordinal metric: {}\".format(krippendorff.alpha(reliability_data=all_raters_score ,level_of_measurement='ordinal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:32:42.705011Z",
     "start_time": "2021-06-16T08:32:42.693916Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_alpha_for_4_raters_in_one_group_question(all_scores):\n",
    "    approaches=['cocogum', 'ast_att_gru', 'astnn', 'rencos']\n",
    "    for aspect in range(3):\n",
    "        for approach in approaches:\n",
    "            get_alpha_for_4_raters_in_one_group_question_one_approach( all_scores, approach, aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T08:32:43.053347Z",
     "start_time": "2021-06-16T08:32:43.036615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cocogum in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in informative: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in naturalness: Krippendorff's alpha for ordinal metric: 0.5966803278688524\n",
      " astnn in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in naturalness: Krippendorff's alpha for ordinal metric: 1.0\n",
      " cocogum in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " ast_att_gru in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " astnn in similarity: Krippendorff's alpha for ordinal metric: 1.0\n",
      " rencos in similarity: Krippendorff's alpha for ordinal metric: 1.0\n"
     ]
    }
   ],
   "source": [
    " get_alpha_for_4_raters_in_one_group_question(all_scores1_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
