{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate cliffs delta effect size\n",
    "### From https://github.com/neilernst/cliffsDelta/blob/master/cliffsDelta.py\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "def cliffsDelta(lst1, lst2, **dull):\n",
    "\n",
    "    \"\"\"Returns delta and true if there are more than 'dull' differences\"\"\"\n",
    "    if not dull:\n",
    "        dull = {'small': 0.147, 'medium': 0.33, 'large': 0.474} # effect sizes from (Hess and Kromrey, 2004)\n",
    "    m, n = len(lst1), len(lst2)\n",
    "    lst2 = sorted(lst2)\n",
    "    j = more = less = 0\n",
    "    for repeats, x in runs(sorted(lst1)):\n",
    "        while j <= (n - 1) and lst2[j] < x:\n",
    "            j += 1\n",
    "        more += j*repeats\n",
    "        while j <= (n - 1) and lst2[j] == x:\n",
    "            j += 1\n",
    "        less += (n - j)*repeats\n",
    "    d = (more - less) / (m*n)\n",
    "    size = lookup_size(d, dull)\n",
    "    return d, size\n",
    "\n",
    "\n",
    "def lookup_size(delta: float, dull: dict) -> str:\n",
    "    \"\"\"\n",
    "    :type delta: float\n",
    "    :type dull: dict, a dictionary of small, medium, large thresholds.\n",
    "    \"\"\"\n",
    "    delta = abs(delta)\n",
    "    if delta < dull['small']:\n",
    "        return 'negligible'\n",
    "    if dull['small'] <= delta < dull['medium']:\n",
    "        return 'small'\n",
    "    if dull['medium'] <= delta < dull['large']:\n",
    "        return 'medium'\n",
    "    if delta >= dull['large']:\n",
    "        return 'large'\n",
    "\n",
    "\n",
    "def runs(lst):\n",
    "    \"\"\"Iterator, chunks repeated values\"\"\"\n",
    "    for j, two in enumerate(lst):\n",
    "        if j == 0:\n",
    "            one, i = two, 0\n",
    "        if one != two:\n",
    "            yield j - i, one\n",
    "            i = j\n",
    "        one = two\n",
    "    yield j - i + 1, two\n",
    "\n",
    "    \n",
    "### calculate wilcoxon pvalue\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def wilcoxon_signed_rank_test(y1, y2):\n",
    "    statistic,pvalue = stats.wilcoxon(y1, y2)\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y1,y2):\n",
    "    pvalue = wilcoxon_signed_rank_test(y1, y2)\n",
    "    d, size = cliffsDelta(y1, y2)\n",
    "    return  pvalue, d, size\n",
    "\n",
    "\n",
    "def get_pvalue_and_effect_size(all_score):\n",
    "    models_name = list(all_score)\n",
    "    for i in range(len( models_name )):\n",
    "        for j in range(i+1,len( models_name )):\n",
    "            pvalue, d, size = get_score(all_score[models_name[i]],all_score[models_name[j]])\n",
    "            print(\"{} and {}, pvalue:{}, cliffsDelta:{}, effect size:{}\".format(models_name[i],models_name[j],pvalue, d, size))\n",
    "\n",
    "\n",
    "def get_all_model_score(path,question_cnt = 50):\n",
    "    data_frame=pd.read_excel(path)\n",
    "    result = {}\n",
    "    \n",
    "    user_cnt = len(data_frame[\"ID\"])\n",
    "    for i in range(user_cnt):\n",
    "        for q in range(question_cnt):\n",
    "            cocogum , ast_att_gru, astnn, rencos = list(data_frame.loc[i])[5+4*q:9+4*q]\n",
    "            key = \"Q_\" + str(q)\n",
    "            if key in result:\n",
    "                result[ key][ \"cocogum\" ].append(cocogum)\n",
    "                result[ key][ \"ast_att_gru\" ].append( ast_att_gru)\n",
    "                result[ key][ \"astnn\" ].append(astnn)\n",
    "                result[ key][ \"rencos\" ].append(rencos)\n",
    "            else:\n",
    "                result[ key] = {}\n",
    "                result[ key][ \"cocogum\" ] = [cocogum]\n",
    "                result[ key][ \"ast_att_gru\" ] = [ast_att_gru]\n",
    "                result[ key][ \"astnn\" ] = [astnn]\n",
    "                result[ key][ \"rencos\" ] = [rencos]\n",
    "\n",
    "    cocogum_scores = []\n",
    "    ast_att_gru_scores = []\n",
    "    astnn_scores = []\n",
    "    rencos_scores = []\n",
    "    for q, four_score in result.items():\n",
    "        cocogum_scores.extend(four_score[\"cocogum\"])\n",
    "        ast_att_gru_scores.extend(four_score[\"ast_att_gru\"])\n",
    "        astnn_scores.extend(four_score[\"astnn\"])\n",
    "        rencos_scores.extend(four_score[\"rencos\"])\n",
    "\n",
    "    all_score = {\"cocogum\":cocogum_scores,\"ast_att_gru\":ast_att_gru_scores,\"astnn\":astnn_scores,\"rencos\":rencos_scores }\n",
    "    return all_score\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_distribution(four_model_score):\n",
    "    print('-' * 90)\n",
    "    print(\"model type \\t\", \"1\\t\" ,\" 2\\t\", \"3\\t\", \"4\\t\" ,\"5\\t\" ,\"Avg\\t\",\"≥4\\t\", \"≥3\\t\", \"≤2\\t\")\n",
    "    for k in four_model_score:\n",
    "        result = Counter(four_model_score[k])\n",
    "        avg = np.mean(four_model_score[k])\n",
    "        print(k,\"  \\t\" ,result[1],\"\\t\"  ,result[2], \"\\t\" ,result[3],\"\\t\"  ,result[4],\"\\t\" ,result[5],\"\\t\" ,  round(   avg ,2),\"\\t\" ,\\\n",
    "              result[4]+result[5],\"\\t\" , result[3]+ result[4]+result[5],\"\\t\" , result[1]+ result[2],\"\\t\" )\n",
    "    print('-' * 90)\n",
    "\n",
    "def print_all(path,question_cnt = 50):\n",
    "    all_score = get_all_model_score(path,question_cnt = 50)\n",
    "    print_distribution(all_score)\n",
    "    get_pvalue_and_effect_size(all_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distribution, pvalue, and effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "model type \t 1\t  2\t 3\t 4\t 5\t Avg\t ≥4\t ≥3\t ≤2\t\n",
      "cocogum   \t 87 \t 147 \t 308 \t 259 \t 199 \t 3.34 \t 458 \t 766 \t 234 \t\n",
      "ast_att_gru   \t 103 \t 236 \t 312 \t 248 \t 101 \t 3.01 \t 349 \t 661 \t 339 \t\n",
      "astnn   \t 320 \t 286 \t 189 \t 130 \t 75 \t 2.35 \t 205 \t 394 \t 606 \t\n",
      "rencos   \t 254 \t 278 \t 209 \t 170 \t 89 \t 2.56 \t 259 \t 468 \t 532 \t\n",
      "------------------------------------------------------------------------------------------\n",
      "cocogum and ast_att_gru, pvalue:8.246301215039014e-19, cliffsDelta:0.158206, effect size:small\n",
      "cocogum and astnn, pvalue:6.28639812864945e-73, cliffsDelta:0.424025, effect size:medium\n",
      "cocogum and rencos, pvalue:3.96856899773712e-52, cliffsDelta:0.337881, effect size:medium\n",
      "ast_att_gru and astnn, pvalue:1.2434481056260308e-47, cliffsDelta:0.309593, effect size:small\n",
      "ast_att_gru and rencos, pvalue:9.878010940157551e-25, cliffsDelta:0.211541, effect size:small\n",
      "astnn and rencos, pvalue:7.803578364015607e-08, cliffsDelta:-0.095242, effect size:negligible\n"
     ]
    }
   ],
   "source": [
    "print_all(r\"Source code summarization human evaluation（random50)(new)(1-20).xlsx\",question_cnt=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "model type \t 1\t  2\t 3\t 4\t 5\t Avg\t ≥4\t ≥3\t ≤2\t\n",
      "cocogum   \t 97 \t 188 \t 379 \t 306 \t 230 \t 3.32 \t 536 \t 915 \t 285 \t\n",
      "ast_att_gru   \t 110 \t 285 \t 392 \t 293 \t 120 \t 3.02 \t 413 \t 805 \t 395 \t\n",
      "astnn   \t 362 \t 374 \t 238 \t 148 \t 78 \t 2.34 \t 226 \t 464 \t 736 \t\n",
      "rencos   \t 289 \t 331 \t 273 \t 207 \t 100 \t 2.58 \t 307 \t 580 \t 620 \t\n",
      "------------------------------------------------------------------------------------------\n",
      "cocogum and ast_att_gru, pvalue:7.2976289202135e-18, cliffsDelta:0.14534027777777778, effect size:negligible\n",
      "cocogum and astnn, pvalue:6.241293621443663e-88, cliffsDelta:0.43407222222222225, effect size:medium\n",
      "cocogum and rencos, pvalue:5.319783228033325e-56, cliffsDelta:0.3272291666666667, effect size:small\n",
      "ast_att_gru and astnn, pvalue:5.438485643970364e-59, cliffsDelta:0.33044305555555553, effect size:medium\n",
      "ast_att_gru and rencos, pvalue:8.739053704851886e-28, cliffsDelta:0.21104166666666666, effect size:small\n",
      "astnn and rencos, pvalue:1.5071209005529993e-11, cliffsDelta:-0.11177638888888888, effect size:negligible\n"
     ]
    }
   ],
   "source": [
    "print_all(r\"Source code summarization human evaluation（random50)(new)(1-24).xlsx\",question_cnt=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
