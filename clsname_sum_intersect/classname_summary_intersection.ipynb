{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'repo': 'ReactiveX/RxJava', 'path': 'src/main/java/io/reactivex/internal/observers/QueueDrainObserver.java', 'func_name': 'QueueDrainObserver.fastPathOrderedEmit', 'original_string': 'protected final void fastPathOrderedEmit(U value, boolean delayError, Disposable disposable) {\\n        final Observer<? super V> observer = downstream;\\n        final SimplePlainQueue<U> q = queue;\\n\\n        if (wip.get() == 0 && wip.compareAndSet(0, 1)) {\\n            if (q.isEmpty()) {\\n                accept(observer, value);\\n                if (leave(-1) == 0) {\\n                    return;\\n                }\\n            } else {\\n                q.offer(value);\\n            }\\n        } else {\\n            q.offer(value);\\n            if (!enter()) {\\n                return;\\n            }\\n        }\\n        QueueDrainHelper.drainLoop(q, observer, delayError, disposable, this);\\n    }', 'language': 'java', 'code': 'protected final void fastPathOrderedEmit(U value, boolean delayError, Disposable disposable) {\\n        final Observer<? super V> observer = downstream;\\n        final SimplePlainQueue<U> q = queue;\\n\\n        if (wip.get() == 0 && wip.compareAndSet(0, 1)) {\\n            if (q.isEmpty()) {\\n                accept(observer, value);\\n                if (leave(-1) == 0) {\\n                    return;\\n                }\\n            } else {\\n                q.offer(value);\\n            }\\n        } else {\\n            q.offer(value);\\n            if (!enter()) {\\n                return;\\n            }\\n        }\\n        QueueDrainHelper.drainLoop(q, observer, delayError, disposable, this);\\n    }', 'code_tokens': ['protected', 'final', 'void', 'fastPathOrderedEmit', '(', 'U', 'value', ',', 'boolean', 'delayError', ',', 'Disposable', 'disposable', ')', '{', 'final', 'Observer', '<', '?', 'super', 'V', '>', 'observer', '=', 'downstream', ';', 'final', 'SimplePlainQueue', '<', 'U', '>', 'q', '=', 'queue', ';', 'if', '(', 'wip', '.', 'get', '(', ')', '==', '0', '&&', 'wip', '.', 'compareAndSet', '(', '0', ',', '1', ')', ')', '{', 'if', '(', 'q', '.', 'isEmpty', '(', ')', ')', '{', 'accept', '(', 'observer', ',', 'value', ')', ';', 'if', '(', 'leave', '(', '-', '1', ')', '==', '0', ')', '{', 'return', ';', '}', '}', 'else', '{', 'q', '.', 'offer', '(', 'value', ')', ';', '}', '}', 'else', '{', 'q', '.', 'offer', '(', 'value', ')', ';', 'if', '(', '!', 'enter', '(', ')', ')', '{', 'return', ';', '}', '}', 'QueueDrainHelper', '.', 'drainLoop', '(', 'q', ',', 'observer', ',', 'delayError', ',', 'disposable', ',', 'this', ')', ';', '}'], 'docstring': 'Makes sure the fast-path emits in order.\\n@param value the value to emit or queue up\\n@param delayError if true, errors are delayed until the source has terminated\\n@param disposable the resource to dispose if the drain terminates', 'docstring_tokens': ['Makes', 'sure', 'the', 'fast', '-', 'path', 'emits', 'in', 'order', '.'], 'sha': 'ac84182aa2bd866b53e01c8e3fe99683b882c60e', 'url': 'https://github.com/ReactiveX/RxJava/blob/ac84182aa2bd866b53e01c8e3fe99683b882c60e/src/main/java/io/reactivex/internal/observers/QueueDrainObserver.java#L88-L108', 'partition': 'test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yanlwang/anaconda3/bin/python\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/casics/spiral.git\n",
      "  Cloning https://github.com/casics/spiral.git to /tmp/pip-req-build-j1l_75uw\n",
      "  Running command git clone -q https://github.com/casics/spiral.git /tmp/pip-req-build-j1l_75uw\n",
      "Requirement already satisfied: nltk>=3.2.1 in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from spiral==1.1.0) (3.5)\n",
      "Requirement already satisfied: humanize>=0.5.1 in /home/yanlwang/.local/lib/python3.8/site-packages (from spiral==1.1.0) (3.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/yanlwang/.local/lib/python3.8/site-packages (from spiral==1.1.0) (1.1.0)\n",
      "Requirement already satisfied: setuptools>=38.5.1 in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from spiral==1.1.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from spiral==1.1.0) (1.15.0)\n",
      "Requirement already satisfied: plac>=0.9.6 in /home/yanlwang/.local/lib/python3.8/site-packages (from spiral==1.1.0) (1.3.3)\n",
      "Requirement already satisfied: pytest>=3.0.5 in /home/yanlwang/.local/lib/python3.8/site-packages (from spiral==1.1.0) (6.2.3)\n",
      "Requirement already satisfied: click in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->spiral==1.1.0) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->spiral==1.1.0) (4.50.2)\n",
      "Requirement already satisfied: regex in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->spiral==1.1.0) (2020.10.15)\n",
      "Requirement already satisfied: joblib in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->spiral==1.1.0) (0.17.0)\n",
      "Requirement already satisfied: iniconfig in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from pytest>=3.0.5->spiral==1.1.0) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from pytest>=3.0.5->spiral==1.1.0) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from pytest>=3.0.5->spiral==1.1.0) (1.9.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from pytest>=3.0.5->spiral==1.1.0) (20.3.0)\n",
      "Requirement already satisfied: packaging in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from pytest>=3.0.5->spiral==1.1.0) (20.4)\n",
      "Requirement already satisfied: toml in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from pytest>=3.0.5->spiral==1.1.0) (0.10.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/yanlwang/anaconda3/lib/python3.8/site-packages (from packaging->pytest>=3.0.5->spiral==1.1.0) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!pip install git+https://github.com/casics/spiral.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download CodeSearchNet dataset. only run once\n",
    "# !wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/java.zip\n",
    "# !unzip java.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['final/jsonl/train/java_train_2.jsonl', 'final/jsonl/train/java_train_9.jsonl', 'final/jsonl/train/java_train_12.jsonl', 'final/jsonl/train/java_train_10.jsonl', 'final/jsonl/train/java_train_6.jsonl', 'final/jsonl/train/java_train_4.jsonl', 'final/jsonl/train/java_train_7.jsonl', 'final/jsonl/train/java_train_3.jsonl', 'final/jsonl/train/java_train_1.jsonl', 'final/jsonl/train/java_train_14.jsonl', 'final/jsonl/train/java_train_15.jsonl', 'final/jsonl/train/java_train_11.jsonl', 'final/jsonl/train/java_train_13.jsonl', 'final/jsonl/train/java_train_5.jsonl', 'final/jsonl/train/java_train_8.jsonl', 'final/jsonl/train/java_train_0.jsonl']\n",
      "['final/jsonl/valid/java_valid_0.jsonl.gz']\n",
      "['final/jsonl/test/java_test_0.jsonl']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "folder = 'final'\n",
    "train,valid,test=[],[],[]\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        temp=os.path.join(root,file)\n",
    "        if '.jsonl' in temp:\n",
    "            if 'train' in temp:\n",
    "                train.append(temp)\n",
    "            elif 'valid' in temp:\n",
    "                valid.append(temp)\n",
    "            elif 'test' in temp:\n",
    "                test.append(temp)   \n",
    "\n",
    "print(train)\n",
    "print(valid)\n",
    "print(test)\n",
    "\n",
    "# train_data,valid_data,test_data={},{},{}\n",
    "train_clsname, valid_clsname, test_clsname = [],[],[]\n",
    "train_sum, valid_sum, test_sum = [],[],[]\n",
    "# for files, data in [[test,test_data]]: #[[train,train_data],[valid,valid_data],[test,test_data]]:\n",
    "for file in test:\n",
    "    if '.gz' in file:\n",
    "        os.system(\"gzip -d {}\".format(file))\n",
    "        file=file.replace('.gz','')\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            js=json.loads(line)\n",
    "            test_clsname.append(js['func_name'].split('.')[0])\n",
    "            test_sum.append(js['docstring_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in train:\n",
    "    if '.gz' in file:\n",
    "        os.system(\"gzip -d {}\".format(file))\n",
    "        file=file.replace('.gz','')\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            js=json.loads(line)\n",
    "            train_clsname.append(js['func_name'].split('.')[0])\n",
    "            train_sum.append(js['docstring_tokens'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in valid:\n",
    "    if '.gz' in file:\n",
    "        os.system(\"gzip -d {}\".format(file))\n",
    "        file=file.replace('.gz','')\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            js=json.loads(line)\n",
    "            valid_clsname.append(js['func_name'].split('.')[0])\n",
    "            valid_sum.append(js['docstring_tokens'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26909\n",
      "26909\n",
      "['Makes', 'sure', 'the', 'fast', '-', 'path', 'emits', 'in', 'order', '.']\n"
     ]
    }
   ],
   "source": [
    "print(len(test_clsname))\n",
    "print(len(test_sum))\n",
    "print(test_sum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('test', exist_ok=True)\n",
    "os.makedirs('train', exist_ok=True)\n",
    "os.makedirs('valid', exist_ok=True)\n",
    "with open('test/sum.pkl', 'wb') as f:\n",
    "    pickle.dump(test_sum, f)\n",
    "with open('test/clsname.pkl', 'wb') as f:\n",
    "    pickle.dump(test_clsname, f)\n",
    "with open('train/sum.pkl', 'wb') as f:\n",
    "    pickle.dump(train_sum, f)\n",
    "with open('train/clsname.pkl', 'wb') as f:\n",
    "    pickle.dump(train_clsname, f)\n",
    "with open('valid/sum.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_sum, f)\n",
    "with open('valid/clsname.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_clsname, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "from spiral import ronin\n",
    "from multiprocessing import cpu_count, Pool\n",
    "import nltk.stem\n",
    "import copy\n",
    "\n",
    "\n",
    "def array_split(original_data, core_num):\n",
    "    data = []\n",
    "    total_size = len(original_data)\n",
    "    per_core_size = math.ceil(total_size / core_num)\n",
    "    for i in range(core_num):\n",
    "        lower_bound = i * per_core_size\n",
    "        upper_bound = min((i + 1) * per_core_size, total_size)\n",
    "        data.append(original_data[lower_bound:upper_bound])\n",
    "    return data\n",
    "\n",
    "\n",
    "def list_flatten(li):\n",
    "    flatten = itertools.chain.from_iterable\n",
    "    return list(flatten(li))\n",
    "\n",
    "\n",
    "def spiral_split(str_arr):\n",
    "    \"\"\"\n",
    "    split tokens in a string array with spiral ronin.\n",
    "    :param str_arr: a string array, for example: ['readUTF8stream']\n",
    "    :return: ['read', 'utf8', 'stream']\n",
    "    \"\"\"\n",
    "    ronin_split = ronin.split\n",
    "    return list(chain(*[[tok.lower() for tok in ronin_split(s)] for s in str_arr]))\n",
    "\n",
    "\n",
    "def lower_case_str_arr(str_arr):\n",
    "    return [tok.lower() for tok in str_arr]\n",
    "\n",
    "\n",
    "def split_and_lowercase(str_arr):\n",
    "    return spiral_split(lower_case_str_arr(str_arr))\n",
    "\n",
    "\n",
    "def split_and_lowercase_lists(seqs):\n",
    "    return [split_and_lowercase(seq) for seq in seqs]\n",
    "\n",
    "\n",
    "def split_and_lowercase_lists_parallel(seqs):\n",
    "    cores = cpu_count()\n",
    "    pool = Pool(cores)\n",
    "    seqs_split = array_split(seqs, cores)\n",
    "    results = pool.map(split_and_lowercase_lists, seqs_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return list_flatten(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9345\n",
      "0.3473\n"
     ]
    }
   ],
   "source": [
    "# intersection of test_sum_si_lc with test_clsname_si_lc\n",
    "test_sum = pickle.load(open('test/sum.pkl', 'rb'))\n",
    "test_clsname = pickle.load(open('test/clsname.pkl', 'rb'))\n",
    "\n",
    "test_sum_si_lc = split_and_lowercase_lists_parallel(test_sum)\n",
    "test_clsname = [[t] for t in test_clsname]\n",
    "test_clsname_si_lc = split_and_lowercase_lists_parallel(test_clsname)\n",
    "\n",
    "count = 0\n",
    "for (summary, clsname) in zip(test_sum_si_lc, test_clsname_si_lc):\n",
    "    intersect = set(summary).intersection(clsname)\n",
    "    if (len(intersect) != 0):\n",
    "        count += 1 \n",
    "\n",
    "print(count)\n",
    "print(round(1.0*count/len(test_sum), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160280\n",
      "0.3527\n"
     ]
    }
   ],
   "source": [
    "# intersection of train_sum_si_lc with train_clsname_si_lc\n",
    "train_sum = pickle.load(open('train/sum.pkl', 'rb'))\n",
    "train_clsname = pickle.load(open('train/clsname.pkl', 'rb'))\n",
    "\n",
    "train_sum_si_lc = split_and_lowercase_lists_parallel(train_sum)\n",
    "train_clsname = [[t] for t in train_clsname]\n",
    "train_clsname_si_lc = split_and_lowercase_lists_parallel(train_clsname)\n",
    "\n",
    "count = 0\n",
    "for (summary, clsname) in zip(train_sum_si_lc, train_clsname_si_lc):\n",
    "    intersect = set(summary).intersection(clsname)\n",
    "    if (len(intersect) != 0):\n",
    "        count += 1 \n",
    "\n",
    "print(count)\n",
    "print(round(1.0*count/len(train_sum), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5567\n",
      "0.3632\n"
     ]
    }
   ],
   "source": [
    "# intersection of valid_sum_si_lc with valid_clsname_si_lc\n",
    "valid_sum = pickle.load(open('valid/sum.pkl', 'rb'))\n",
    "valid_clsname = pickle.load(open('valid/clsname.pkl', 'rb'))\n",
    "\n",
    "valid_sum_si_lc = split_and_lowercase_lists_parallel(valid_sum)\n",
    "valid_clsname = [[t] for t in valid_clsname]\n",
    "valid_clsname_si_lc = split_and_lowercase_lists_parallel(valid_clsname)\n",
    "\n",
    "count = 0\n",
    "for (summary, clsname) in zip(valid_sum_si_lc, valid_clsname_si_lc):\n",
    "    intersect = set(summary).intersection(clsname)\n",
    "    if (len(intersect) != 0):\n",
    "        count += 1 \n",
    "\n",
    "print(count)\n",
    "print(round(1.0*count/len(valid_sum), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
